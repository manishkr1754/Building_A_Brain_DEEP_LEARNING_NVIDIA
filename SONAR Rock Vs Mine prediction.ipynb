{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/manishkr1754/sonar-rock-vs-mine-prediction?scriptVersionId=142552867\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n<center><h1>SONAR Rock Vs Mine Prediction</h1></center>\n<center><h3>Part of 30 Days 30 ML Projects Challenge</h3></center>\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 1) Understanding Problem Statement\n---\n\nThe SONAR Rock Vs Mine Prediction falls under **Classication Machine Learning Problem**. The project aims to develop a machine learning model capable of accurately distinguishing between metal cylinders(mines) and rocks based on SONAR return data.\n\n## 2) Understanding Data\n---\n\nThe project is based on SONAR return data. Each data point consists of a set of 60 numerical values ranging between 0 to 1 representing the energy within specific frequency bands over time. The labels are 'M' for mines and 'R' for rock. The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.\n","metadata":{}},{"cell_type":"markdown","source":"## 3) Getting System Ready\n---\nImporting required libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# for model buidling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## 4) Data Eyeballing\n---","metadata":{}},{"cell_type":"markdown","source":"### Loading Data","metadata":{}},{"cell_type":"code","source":"sonar_data = pd.read_csv('Datasets/Day1_Data_Sonar_Data.csv', header=None)","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sonar_data","metadata":{},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>0.0187</td>\n","      <td>0.0346</td>\n","      <td>0.0168</td>\n","      <td>0.0177</td>\n","      <td>0.0393</td>\n","      <td>0.1630</td>\n","      <td>0.2028</td>\n","      <td>0.1694</td>\n","      <td>0.2328</td>\n","      <td>0.2684</td>\n","      <td>...</td>\n","      <td>0.0116</td>\n","      <td>0.0098</td>\n","      <td>0.0199</td>\n","      <td>0.0033</td>\n","      <td>0.0101</td>\n","      <td>0.0065</td>\n","      <td>0.0115</td>\n","      <td>0.0193</td>\n","      <td>0.0157</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>204</th>\n","      <td>0.0323</td>\n","      <td>0.0101</td>\n","      <td>0.0298</td>\n","      <td>0.0564</td>\n","      <td>0.0760</td>\n","      <td>0.0958</td>\n","      <td>0.0990</td>\n","      <td>0.1018</td>\n","      <td>0.1030</td>\n","      <td>0.2154</td>\n","      <td>...</td>\n","      <td>0.0061</td>\n","      <td>0.0093</td>\n","      <td>0.0135</td>\n","      <td>0.0063</td>\n","      <td>0.0063</td>\n","      <td>0.0034</td>\n","      <td>0.0032</td>\n","      <td>0.0062</td>\n","      <td>0.0067</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>0.0522</td>\n","      <td>0.0437</td>\n","      <td>0.0180</td>\n","      <td>0.0292</td>\n","      <td>0.0351</td>\n","      <td>0.1171</td>\n","      <td>0.1257</td>\n","      <td>0.1178</td>\n","      <td>0.1258</td>\n","      <td>0.2529</td>\n","      <td>...</td>\n","      <td>0.0160</td>\n","      <td>0.0029</td>\n","      <td>0.0051</td>\n","      <td>0.0062</td>\n","      <td>0.0089</td>\n","      <td>0.0140</td>\n","      <td>0.0138</td>\n","      <td>0.0077</td>\n","      <td>0.0031</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>206</th>\n","      <td>0.0303</td>\n","      <td>0.0353</td>\n","      <td>0.0490</td>\n","      <td>0.0608</td>\n","      <td>0.0167</td>\n","      <td>0.1354</td>\n","      <td>0.1465</td>\n","      <td>0.1123</td>\n","      <td>0.1945</td>\n","      <td>0.2354</td>\n","      <td>...</td>\n","      <td>0.0086</td>\n","      <td>0.0046</td>\n","      <td>0.0126</td>\n","      <td>0.0036</td>\n","      <td>0.0035</td>\n","      <td>0.0034</td>\n","      <td>0.0079</td>\n","      <td>0.0036</td>\n","      <td>0.0048</td>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>207</th>\n","      <td>0.0260</td>\n","      <td>0.0363</td>\n","      <td>0.0136</td>\n","      <td>0.0272</td>\n","      <td>0.0214</td>\n","      <td>0.0338</td>\n","      <td>0.0655</td>\n","      <td>0.1400</td>\n","      <td>0.1843</td>\n","      <td>0.2354</td>\n","      <td>...</td>\n","      <td>0.0146</td>\n","      <td>0.0129</td>\n","      <td>0.0047</td>\n","      <td>0.0039</td>\n","      <td>0.0061</td>\n","      <td>0.0040</td>\n","      <td>0.0036</td>\n","      <td>0.0061</td>\n","      <td>0.0115</td>\n","      <td>M</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>208 rows Ã— 61 columns</p>\n","</div>"],"text/plain":["         0       1       2       3       4       5       6       7       8   \\\n","0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n","203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n","204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n","205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n","206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n","207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n","\n","         9   ...      51      52      53      54      55      56      57  \\\n","0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n","203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n","204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n","205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n","206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n","207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n","\n","         58      59  60  \n","0    0.0090  0.0032   R  \n","1    0.0052  0.0044   R  \n","2    0.0095  0.0078   R  \n","3    0.0040  0.0117   R  \n","4    0.0107  0.0094   R  \n","..      ...     ...  ..  \n","203  0.0193  0.0157   M  \n","204  0.0062  0.0067   M  \n","205  0.0077  0.0031   M  \n","206  0.0036  0.0048   M  \n","207  0.0061  0.0115   M  \n","\n","[208 rows x 61 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"print('The size of Dataframe is: ', sonar_data.shape)\nprint('-'*100)\nprint('The Column Name, Record Count and Data Types are as follows: ')\nsonar_data.info()\nprint('-'*100)","metadata":{},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"The size of Dataframe is:  (208, 61)\n\n----------------------------------------------------------------------------------------------------\n\nThe Column Name, Record Count and Data Types are as follows: \n\n<class 'pandas.core.frame.DataFrame'>\n\nRangeIndex: 208 entries, 0 to 207\n\nData columns (total 61 columns):\n\n #   Column  Non-Null Count  Dtype  \n\n---  ------  --------------  -----  \n\n 0   0       208 non-null    float64\n\n 1   1       208 non-null    float64\n\n 2   2       208 non-null    float64\n\n 3   3       208 non-null    float64\n\n 4   4       208 non-null    float64\n\n 5   5       208 non-null    float64\n\n 6   6       208 non-null    float64\n\n 7   7       208 non-null    float64\n\n 8   8       208 non-null    float64\n\n 9   9       208 non-null    float64\n\n 10  10      208 non-null    float64\n\n 11  11      208 non-null    float64\n\n 12  12      208 non-null    float64\n\n 13  13      208 non-null    float64\n\n 14  14      208 non-null    float64\n\n 15  15      208 non-null    float64\n\n 16  16      208 non-null    float64\n\n 17  17      208 non-null    float64\n\n 18  18      208 non-null    float64\n\n 19  19      208 non-null    float64\n\n 20  20      208 non-null    float64\n\n 21  21      208 non-null    float64\n\n 22  22      208 non-null    float64\n\n 23  23      208 non-null    float64\n\n 24  24      208 non-null    float64\n\n 25  25      208 non-null    float64\n\n 26  26      208 non-null    float64\n\n 27  27      208 non-null    float64\n\n 28  28      208 non-null    float64\n\n 29  29      208 non-null    float64\n\n 30  30      208 non-null    float64\n\n 31  31      208 non-null    float64\n\n 32  32      208 non-null    float64\n\n 33  33      208 non-null    float64\n\n 34  34      208 non-null    float64\n\n 35  35      208 non-null    float64\n\n 36  36      208 non-null    float64\n\n 37  37      208 non-null    float64\n\n 38  38      208 non-null    float64\n\n 39  39      208 non-null    float64\n\n 40  40      208 non-null    float64\n\n 41  41      208 non-null    float64\n\n 42  42      208 non-null    float64\n\n 43  43      208 non-null    float64\n\n 44  44      208 non-null    float64\n\n 45  45      208 non-null    float64\n\n 46  46      208 non-null    float64\n\n 47  47      208 non-null    float64\n\n 48  48      208 non-null    float64\n\n 49  49      208 non-null    float64\n\n 50  50      208 non-null    float64\n\n 51  51      208 non-null    float64\n\n 52  52      208 non-null    float64\n\n 53  53      208 non-null    float64\n\n 54  54      208 non-null    float64\n\n 55  55      208 non-null    float64\n\n 56  56      208 non-null    float64\n\n 57  57      208 non-null    float64\n\n 58  58      208 non-null    float64\n\n 59  59      208 non-null    float64\n\n 60  60      208 non-null    object \n\ndtypes: float64(60), object(1)\n\nmemory usage: 99.2+ KB\n\n----------------------------------------------------------------------------------------------------\n"}]},{"cell_type":"code","source":"# Defining numerical & categorical columns\nnumeric_features = [feature for feature in sonar_data.columns if sonar_data[feature].dtype != 'O']\ncategorical_features = [feature for feature in sonar_data.columns if sonar_data[feature].dtype == 'O']\n\n# print columns\nprint('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\nprint('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))","metadata":{},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"We have 60 numerical features : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n\n\n\nWe have 1 categorical features : [60]\n"}]},{"cell_type":"code","source":"print('Missing Value Presence in different columns of DataFrame are as follows : ')\nprint('-'*100)\ntotal=sonar_data.isnull().sum().sort_values(ascending=False)\npercent=(sonar_data.isnull().sum()/sonar_data.isnull().count()*100).sort_values(ascending=False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","metadata":{},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"Missing Value Presence in different columns of DataFrame are as follows : \n\n----------------------------------------------------------------------------------------------------\n"},{"execution_count":8,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Total</th>\n","      <th>Percent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>61 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["    Total  Percent\n","0       0      0.0\n","31      0      0.0\n","33      0      0.0\n","34      0      0.0\n","35      0      0.0\n","..    ...      ...\n","25      0      0.0\n","26      0      0.0\n","27      0      0.0\n","28      0      0.0\n","60      0      0.0\n","\n","[61 rows x 2 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"print('Summary Statistics of numerical features for DataFrame are as follows:')\nprint('-'*100)\nsonar_data.describe()","metadata":{},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"Summary Statistics of numerical features for DataFrame are as follows:\n\n----------------------------------------------------------------------------------------------------\n"},{"execution_count":11,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>...</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","      <td>208.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.029164</td>\n","      <td>0.038437</td>\n","      <td>0.043832</td>\n","      <td>0.053892</td>\n","      <td>0.075202</td>\n","      <td>0.104570</td>\n","      <td>0.121747</td>\n","      <td>0.134799</td>\n","      <td>0.178003</td>\n","      <td>0.208259</td>\n","      <td>...</td>\n","      <td>0.016069</td>\n","      <td>0.013420</td>\n","      <td>0.010709</td>\n","      <td>0.010941</td>\n","      <td>0.009290</td>\n","      <td>0.008222</td>\n","      <td>0.007820</td>\n","      <td>0.007949</td>\n","      <td>0.007941</td>\n","      <td>0.006507</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.022991</td>\n","      <td>0.032960</td>\n","      <td>0.038428</td>\n","      <td>0.046528</td>\n","      <td>0.055552</td>\n","      <td>0.059105</td>\n","      <td>0.061788</td>\n","      <td>0.085152</td>\n","      <td>0.118387</td>\n","      <td>0.134416</td>\n","      <td>...</td>\n","      <td>0.012008</td>\n","      <td>0.009634</td>\n","      <td>0.007060</td>\n","      <td>0.007301</td>\n","      <td>0.007088</td>\n","      <td>0.005736</td>\n","      <td>0.005785</td>\n","      <td>0.006470</td>\n","      <td>0.006181</td>\n","      <td>0.005031</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.001500</td>\n","      <td>0.000600</td>\n","      <td>0.001500</td>\n","      <td>0.005800</td>\n","      <td>0.006700</td>\n","      <td>0.010200</td>\n","      <td>0.003300</td>\n","      <td>0.005500</td>\n","      <td>0.007500</td>\n","      <td>0.011300</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000800</td>\n","      <td>0.000500</td>\n","      <td>0.001000</td>\n","      <td>0.000600</td>\n","      <td>0.000400</td>\n","      <td>0.000300</td>\n","      <td>0.000300</td>\n","      <td>0.000100</td>\n","      <td>0.000600</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.013350</td>\n","      <td>0.016450</td>\n","      <td>0.018950</td>\n","      <td>0.024375</td>\n","      <td>0.038050</td>\n","      <td>0.067025</td>\n","      <td>0.080900</td>\n","      <td>0.080425</td>\n","      <td>0.097025</td>\n","      <td>0.111275</td>\n","      <td>...</td>\n","      <td>0.008425</td>\n","      <td>0.007275</td>\n","      <td>0.005075</td>\n","      <td>0.005375</td>\n","      <td>0.004150</td>\n","      <td>0.004400</td>\n","      <td>0.003700</td>\n","      <td>0.003600</td>\n","      <td>0.003675</td>\n","      <td>0.003100</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.022800</td>\n","      <td>0.030800</td>\n","      <td>0.034300</td>\n","      <td>0.044050</td>\n","      <td>0.062500</td>\n","      <td>0.092150</td>\n","      <td>0.106950</td>\n","      <td>0.112100</td>\n","      <td>0.152250</td>\n","      <td>0.182400</td>\n","      <td>...</td>\n","      <td>0.013900</td>\n","      <td>0.011400</td>\n","      <td>0.009550</td>\n","      <td>0.009300</td>\n","      <td>0.007500</td>\n","      <td>0.006850</td>\n","      <td>0.005950</td>\n","      <td>0.005800</td>\n","      <td>0.006400</td>\n","      <td>0.005300</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.035550</td>\n","      <td>0.047950</td>\n","      <td>0.057950</td>\n","      <td>0.064500</td>\n","      <td>0.100275</td>\n","      <td>0.134125</td>\n","      <td>0.154000</td>\n","      <td>0.169600</td>\n","      <td>0.233425</td>\n","      <td>0.268700</td>\n","      <td>...</td>\n","      <td>0.020825</td>\n","      <td>0.016725</td>\n","      <td>0.014900</td>\n","      <td>0.014500</td>\n","      <td>0.012100</td>\n","      <td>0.010575</td>\n","      <td>0.010425</td>\n","      <td>0.010350</td>\n","      <td>0.010325</td>\n","      <td>0.008525</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.137100</td>\n","      <td>0.233900</td>\n","      <td>0.305900</td>\n","      <td>0.426400</td>\n","      <td>0.401000</td>\n","      <td>0.382300</td>\n","      <td>0.372900</td>\n","      <td>0.459000</td>\n","      <td>0.682800</td>\n","      <td>0.710600</td>\n","      <td>...</td>\n","      <td>0.100400</td>\n","      <td>0.070900</td>\n","      <td>0.039000</td>\n","      <td>0.035200</td>\n","      <td>0.044700</td>\n","      <td>0.039400</td>\n","      <td>0.035500</td>\n","      <td>0.044000</td>\n","      <td>0.036400</td>\n","      <td>0.043900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows Ã— 60 columns</p>\n","</div>"],"text/plain":["               0           1           2           3           4           5   \\\n","count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n","mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n","std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n","min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n","25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n","50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n","75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n","max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n","\n","               6           7           8           9   ...          50  \\\n","count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n","mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n","std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n","min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n","25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n","50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n","75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n","max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n","\n","               51          52          53          54          55          56  \\\n","count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n","mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n","std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n","min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n","25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n","50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n","75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n","max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n","\n","               57          58          59  \n","count  208.000000  208.000000  208.000000  \n","mean     0.007949    0.007941    0.006507  \n","std      0.006470    0.006181    0.005031  \n","min      0.000300    0.000100    0.000600  \n","25%      0.003600    0.003675    0.003100  \n","50%      0.005800    0.006400    0.005300  \n","75%      0.010350    0.010325    0.008525  \n","max      0.044000    0.036400    0.043900  \n","\n","[8 rows x 60 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"print('Summary Statistics of categorical features for DataFrame are as follows:')\nprint('-'*100)\nsonar_data.describe(include= 'object')","metadata":{},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"Summary Statistics of categorical features for DataFrame are as follows:\n\n----------------------------------------------------------------------------------------------------\n"},{"execution_count":12,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>208</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>111</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         60\n","count   208\n","unique    2\n","top       M\n","freq    111"]},"metadata":{}}]},{"cell_type":"code","source":"sonar_data[60].value_counts()","metadata":{},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":["60\n","M    111\n","R     97\n","Name: count, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"- Here **`M`** stands for **Mine** and **`R`** stands for **Rock**","metadata":{}},{"cell_type":"markdown","source":"### No Data Cleaning and Preprocessing Needed","metadata":{}},{"cell_type":"markdown","source":"## 5) Model Building : Logistic Regression\n---","metadata":{}},{"cell_type":"markdown","source":"### Creating Feature Matrix (Independent Variables) & Target Variable (Dependent Variable)","metadata":{}},{"cell_type":"code","source":"X=sonar_data.drop(columns=60,axis=1)      # Feature Matrix\nX","metadata":{},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0125</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0033</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0241</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0156</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>0.0187</td>\n","      <td>0.0346</td>\n","      <td>0.0168</td>\n","      <td>0.0177</td>\n","      <td>0.0393</td>\n","      <td>0.1630</td>\n","      <td>0.2028</td>\n","      <td>0.1694</td>\n","      <td>0.2328</td>\n","      <td>0.2684</td>\n","      <td>...</td>\n","      <td>0.0203</td>\n","      <td>0.0116</td>\n","      <td>0.0098</td>\n","      <td>0.0199</td>\n","      <td>0.0033</td>\n","      <td>0.0101</td>\n","      <td>0.0065</td>\n","      <td>0.0115</td>\n","      <td>0.0193</td>\n","      <td>0.0157</td>\n","    </tr>\n","    <tr>\n","      <th>204</th>\n","      <td>0.0323</td>\n","      <td>0.0101</td>\n","      <td>0.0298</td>\n","      <td>0.0564</td>\n","      <td>0.0760</td>\n","      <td>0.0958</td>\n","      <td>0.0990</td>\n","      <td>0.1018</td>\n","      <td>0.1030</td>\n","      <td>0.2154</td>\n","      <td>...</td>\n","      <td>0.0051</td>\n","      <td>0.0061</td>\n","      <td>0.0093</td>\n","      <td>0.0135</td>\n","      <td>0.0063</td>\n","      <td>0.0063</td>\n","      <td>0.0034</td>\n","      <td>0.0032</td>\n","      <td>0.0062</td>\n","      <td>0.0067</td>\n","    </tr>\n","    <tr>\n","      <th>205</th>\n","      <td>0.0522</td>\n","      <td>0.0437</td>\n","      <td>0.0180</td>\n","      <td>0.0292</td>\n","      <td>0.0351</td>\n","      <td>0.1171</td>\n","      <td>0.1257</td>\n","      <td>0.1178</td>\n","      <td>0.1258</td>\n","      <td>0.2529</td>\n","      <td>...</td>\n","      <td>0.0155</td>\n","      <td>0.0160</td>\n","      <td>0.0029</td>\n","      <td>0.0051</td>\n","      <td>0.0062</td>\n","      <td>0.0089</td>\n","      <td>0.0140</td>\n","      <td>0.0138</td>\n","      <td>0.0077</td>\n","      <td>0.0031</td>\n","    </tr>\n","    <tr>\n","      <th>206</th>\n","      <td>0.0303</td>\n","      <td>0.0353</td>\n","      <td>0.0490</td>\n","      <td>0.0608</td>\n","      <td>0.0167</td>\n","      <td>0.1354</td>\n","      <td>0.1465</td>\n","      <td>0.1123</td>\n","      <td>0.1945</td>\n","      <td>0.2354</td>\n","      <td>...</td>\n","      <td>0.0042</td>\n","      <td>0.0086</td>\n","      <td>0.0046</td>\n","      <td>0.0126</td>\n","      <td>0.0036</td>\n","      <td>0.0035</td>\n","      <td>0.0034</td>\n","      <td>0.0079</td>\n","      <td>0.0036</td>\n","      <td>0.0048</td>\n","    </tr>\n","    <tr>\n","      <th>207</th>\n","      <td>0.0260</td>\n","      <td>0.0363</td>\n","      <td>0.0136</td>\n","      <td>0.0272</td>\n","      <td>0.0214</td>\n","      <td>0.0338</td>\n","      <td>0.0655</td>\n","      <td>0.1400</td>\n","      <td>0.1843</td>\n","      <td>0.2354</td>\n","      <td>...</td>\n","      <td>0.0181</td>\n","      <td>0.0146</td>\n","      <td>0.0129</td>\n","      <td>0.0047</td>\n","      <td>0.0039</td>\n","      <td>0.0061</td>\n","      <td>0.0040</td>\n","      <td>0.0036</td>\n","      <td>0.0061</td>\n","      <td>0.0115</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>208 rows Ã— 60 columns</p>\n","</div>"],"text/plain":["         0       1       2       3       4       5       6       7       8   \\\n","0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n","203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n","204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n","205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n","206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n","207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n","\n","         9   ...      50      51      52      53      54      55      56  \\\n","0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n","1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n","2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n","3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n","4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n","..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n","203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n","204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n","205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n","206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n","207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n","\n","         57      58      59  \n","0    0.0084  0.0090  0.0032  \n","1    0.0049  0.0052  0.0044  \n","2    0.0164  0.0095  0.0078  \n","3    0.0044  0.0040  0.0117  \n","4    0.0048  0.0107  0.0094  \n","..      ...     ...     ...  \n","203  0.0115  0.0193  0.0157  \n","204  0.0032  0.0062  0.0067  \n","205  0.0138  0.0077  0.0031  \n","206  0.0079  0.0036  0.0048  \n","207  0.0036  0.0061  0.0115  \n","\n","[208 rows x 60 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"y=sonar_data[60]    # Target Variable\ny","metadata":{},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":["0      R\n","1      R\n","2      R\n","3      R\n","4      R\n","      ..\n","203    M\n","204    M\n","205    M\n","206    M\n","207    M\n","Name: 60, Length: 208, dtype: object"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=45)","metadata":{},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(X.shape, X_train.shape, X_test.shape)","metadata":{},"execution_count":20,"outputs":[{"name":"stdout","output_type":"stream","text":"(208, 60) (166, 60) (42, 60)\n"}]},{"cell_type":"code","source":"print(y.shape, y_train.shape, y_test.shape)","metadata":{},"execution_count":21,"outputs":[{"name":"stdout","output_type":"stream","text":"(208,) (166,) (42,)\n"}]},{"cell_type":"markdown","source":"### Model Training","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression()","metadata":{},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#training the Logistic Regression model with training data\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression()"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"#accuracy on training data\nX_train_prediction = model.predict(X_train)\naccuracy_training_data = accuracy_score(X_train_prediction, y_train) ","metadata":{},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print('Accuracy on Training Data : ', accuracy_training_data)","metadata":{},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy on Training Data :  0.8313253012048193\n"}]},{"cell_type":"code","source":"#accuracy on test data\nX_test_prediction = model.predict(X_test)\naccuracy_test_data = accuracy_score(X_test_prediction, y_test) ","metadata":{},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('Accuracy on test data : ',accuracy_test_data )","metadata":{},"execution_count":28,"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy on test data :  0.7857142857142857\n"}]},{"cell_type":"markdown","source":"## 6) Model Comparison for Selection of Best Model\n---\nModel Comparison between **LogisticRegression, SVC, DecisionTreeClassifier** and **RandomForestClassifier**","metadata":{}},{"cell_type":"markdown","source":"### Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"models = [LogisticRegression, SVC, DecisionTreeClassifier, RandomForestClassifier]\naccuracy_scores = []\n\nfor model in models:\n    classifier = model().fit(X_train, y_train)\n    pred = classifier.predict(X_test)\n    accuracy_scores.append(accuracy_score(y_true=y_test, y_pred=pred))","metadata":{},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"classification_model_df = pd.DataFrame({\n    \"Model\": ['Logistic Regression', 'Support Vector Classifier', 'Decision Tree Classifier',\n              'Random Forest Classifier'],\n    \"Accuracy\": accuracy_scores,\n})\n\nclassification_model_df.set_index('Model', inplace=True)\nclassification_model_df","metadata":{},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Logistic Regression</th>\n","      <td>0.785714</td>\n","    </tr>\n","    <tr>\n","      <th>Support Vector Classifier</th>\n","      <td>0.785714</td>\n","    </tr>\n","    <tr>\n","      <th>Decision Tree Classifier</th>\n","      <td>0.690476</td>\n","    </tr>\n","    <tr>\n","      <th>Random Forest Classifier</th>\n","      <td>0.809524</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Accuracy\n","Model                              \n","Logistic Regression        0.785714\n","Support Vector Classifier  0.785714\n","Decision Tree Classifier   0.690476\n","Random Forest Classifier   0.809524"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Inference\n\n- Best Model based on accuracy score only is **Random Forest Classifier**. However, for real life best model selection are not solely based on accuracy score, we need to take into account **other evaluation metrics, business context and model interpretability**.","metadata":{}}]}